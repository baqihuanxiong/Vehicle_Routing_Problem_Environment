{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指派问题简易环境\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境参数\n",
    "N_QC = 3       # 岸桥数量\n",
    "N_ARMG = 2     # 场桥数量\n",
    "N_VEHICLE = 3  # 运输车数量\n",
    "\n",
    "# 距离矩阵，大小为：N_QC + N_ARMG + 1，最后一行/列为车辆起始位置\n",
    "DIST_MAT = np.array([\n",
    "    [0, 1, 2, 4, 6, 3],\n",
    "    [1, 0, 1, 4, 4, 3],\n",
    "    [2, 1, 0, 6, 4, 3],\n",
    "    [4, 4, 6, 0, 1, 3],\n",
    "    [6, 4, 4, 1, 0, 3],\n",
    "    [3, 3, 3, 3, 3, 0]\n",
    "])\n",
    "assert DIST_MAT.shape == (N_QC + N_ARMG + 1, N_QC + N_ARMG + 1)\n",
    "\n",
    "QC_PREPARE_TIME = 30    # 岸桥装/卸箱准备时间\n",
    "QC_LIFT_TIME = 10       # 岸桥吊装时间\n",
    "ARMG_PREPARE_TIME = 20  # 场桥装/卸箱准备时间\n",
    "ARMG_LIFT_TIME = 6      # 场桥吊装时间\n",
    "\n",
    "MIN_IDLE_TIME = 5       # 车辆最短闲置时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    \"\"\"\n",
    "    仿真类负责计算各个设备完成任务的时间，环境依赖仿真推进任务队列的执行。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.equip_state = {i: [] for i in range(N_QC + N_ARMG)}\n",
    "        self.vehicle_position = [N_QC + N_ARMG] * N_VEHICLE\n",
    "        \n",
    "        self.future_events = [(0, i) for i in range(N_VEHICLE)]\n",
    "        self.now = 0\n",
    "    \n",
    "    def current_state(self):\n",
    "        return {\n",
    "            \"equip_state\": self.equip_state,\n",
    "            \"vehicle_position\": self.vehicle_position,\n",
    "            \"future_events\": self.future_events,\n",
    "            \"now\": self.now\n",
    "        }\n",
    "    \n",
    "    def peek_future(self):\n",
    "        return self.future_events[0]\n",
    "    \n",
    "    def predict_travel_time(self, i_vehicle, i_equip):\n",
    "        vehicle_pos = self.vehicle_position[i_vehicle]\n",
    "        return DIST_MAT[vehicle_pos, i_equip] * 10\n",
    "    \n",
    "    def get_equip_state(self, i_equip):\n",
    "        state = self.equip_state[i_equip]\n",
    "        if len(state) == 0:\n",
    "            return 0\n",
    "        return state[-1]\n",
    "    \n",
    "    def do_idle(self, i_vehicle):\n",
    "        recycle_time = self.predict_travel_time(self.vehicle_position[i_vehicle], len(DIST_MAT) - 1)\n",
    "        idle_time = max(recycle_time, MIN_IDLE_TIME)\n",
    "        self.vehicle_position[i_vehicle] = len(DIST_MAT) - 1\n",
    "        return self.now + idle_time\n",
    "    \n",
    "    def do_task(self, task, i_vehicle, phase=1):\n",
    "        i_equip = task[0] if phase == 0 else task[1]\n",
    "        \n",
    "        last_time = self.get_equip_state(i_equip)\n",
    "        prepare_time = QC_PREPARE_TIME if i_equip < N_QC else ARMG_PREPARE_TIME\n",
    "        lift_time = QC_LIFT_TIME if i_equip < N_QC else ARMG_LIFT_TIME\n",
    "        if phase == 0:\n",
    "            arrival_time = self.now + self.predict_travel_time(i_vehicle, i_equip)\n",
    "        else:\n",
    "            depart_time = self.do_task(task, i_vehicle, 0)\n",
    "            arrival_time = depart_time + self.predict_travel_time(i_vehicle, i_equip)\n",
    "        finish_time = max(last_time + prepare_time, arrival_time) + lift_time\n",
    "        \n",
    "        self.equip_state[i_equip].append(finish_time)\n",
    "        self.vehicle_position[i_vehicle] = i_equip\n",
    "        return finish_time\n",
    "        \n",
    "    def resume(self, task):\n",
    "        self.now, i_vehicle = heappop(self.future_events)\n",
    "        if task is None:\n",
    "            next_time = self.do_idle(i_vehicle)\n",
    "        else:\n",
    "            next_time = self.do_task(task, i_vehicle)\n",
    "        heappush(self.future_events, (next_time, i_vehicle))\n",
    "        return next_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation current state: {'equip_state': {0: [], 1: [], 2: [], 3: [], 4: []}, 'vehicle_position': [5, 5, 5], 'future_events': [(0, 0), (0, 1), (0, 2)], 'now': 0}.\n",
      "Vehicle 0 is available at 0s.\n",
      "Task (0, 3) is done.\n",
      "Simulation current state: {'equip_state': {0: [40], 1: [], 2: [], 3: [86], 4: []}, 'vehicle_position': [3, 5, 5], 'future_events': [(0, 1), (0, 2), (86, 0)], 'now': 0}.\n",
      "Vehicle 1 is available at 0s.\n",
      "Task (4, 0) is done.\n",
      "Simulation current state: {'equip_state': {0: [40, 106], 1: [], 2: [], 3: [86], 4: [36]}, 'vehicle_position': [3, 0, 5], 'future_events': [(0, 2), (86, 0), (106, 1)], 'now': 0}.\n",
      "Vehicle 2 is available at 0s.\n",
      "Task (3, 1) is done.\n",
      "Simulation current state: {'equip_state': {0: [40, 106], 1: [162], 2: [], 3: [86, 112], 4: [36]}, 'vehicle_position': [3, 0, 1], 'future_events': [(86, 0), (106, 1), (162, 2)], 'now': 0}.\n",
      "Vehicle 0 is available at 86s.\n",
      "Task (3, 2) is done.\n",
      "Simulation current state: {'equip_state': {0: [40, 106], 1: [162], 2: [208], 3: [86, 112, 138], 4: [36]}, 'vehicle_position': [2, 0, 1], 'future_events': [(106, 1), (162, 2), (208, 0)], 'now': 86}.\n",
      "Vehicle 1 back to origin at 106s.\n",
      "Simulation current state: {'equip_state': {0: [40, 106], 1: [162], 2: [208], 3: [86, 112, 138], 4: [36]}, 'vehicle_position': [2, 5, 1], 'future_events': [(136, 1), (208, 0), (162, 2)], 'now': 106}.\n"
     ]
    }
   ],
   "source": [
    "tasks = [\n",
    "    (0, 3),\n",
    "    (4, 0),\n",
    "    (3, 1),\n",
    "    (3, 2)\n",
    "]\n",
    "simulation = Simulation()\n",
    "for task in tasks:\n",
    "    print(f\"Simulation current state: {simulation.current_state()}.\")\n",
    "    future = simulation.peek_future()\n",
    "    print(f\"Vehicle {future[1]} is available at {future[0]}s.\")\n",
    "    _ = simulation.resume(task)\n",
    "    print(f\"Task {task} is done.\")\n",
    "print(f\"Simulation current state: {simulation.current_state()}.\")\n",
    "future = simulation.peek_future()\n",
    "print(f\"Vehicle {future[1]} back to origin at {future[0]}s.\")\n",
    "_ = simulation.resume(None)\n",
    "print(f\"Simulation current state: {simulation.current_state()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tasks(tasks):\n",
    "    for task in tasks:\n",
    "        assert type(task) is tuple and len(task) == 2\n",
    "        assert task[0] != tasks[1] and 0 <= task[0] < N_QC + N_ARMG and 0 <= task[1] < N_QC + N_ARMG\n",
    "    return tasks\n",
    "\n",
    "def generate_task_group(tasks):\n",
    "    group = {i: [] for i in range(N_QC)}\n",
    "    for i, task in enumerate(tasks):\n",
    "        if task[0] < N_QC:\n",
    "            group[task[0]].append(i)\n",
    "        if task[1] < N_QC:\n",
    "            group[task[1]].append(i)\n",
    "    return group\n",
    "\n",
    "def generate_equip_map(tasks):\n",
    "    equip_map = {}\n",
    "    for i, task in enumerate(tasks):\n",
    "        if task[0] < N_QC:\n",
    "            equip_map[i] = task[0]\n",
    "        if task[1] < N_QC:\n",
    "            equip_map[i] = task[1]\n",
    "    return equip_map\n",
    "    \n",
    "    \n",
    "class Environment:\n",
    "    def __init__(self, tasks):\n",
    "        self.tasks = check_tasks(tasks)\n",
    "        self.task_group = generate_task_group(tasks)\n",
    "        self.equip_map = generate_equip_map(tasks)\n",
    "        \n",
    "        self.action_space = np.arange(len(tasks))\n",
    "        self.observation_space = None\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def get_next_task(self, i_task):\n",
    "        i_equip = self.equip_map[i_task]\n",
    "        for i in range(i_task+1, len(self.tasks)):\n",
    "            if self.equip_map[i] == i_equip:\n",
    "                return i\n",
    "        return None\n",
    "    \n",
    "    def get_selectable_tasks(self):\n",
    "        return np.argwhere(np.sum(self.observation, axis=0) == 2).T[0]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.sim = Simulation()\n",
    "        \n",
    "        self.observation = np.array([\n",
    "            [1 for i in range(len(self.tasks))],\n",
    "            [0 for i in range(len(self.tasks))]\n",
    "        ])\n",
    "        selectable_tasks = [tasks[0] for tasks in self.task_group.values()]\n",
    "        self.observation[1, selectable_tasks] = 1\n",
    "        return self.observation\n",
    "    \n",
    "    def step(self, i_task):\n",
    "        if i_task < 0:\n",
    "            self.sim.resume(None)\n",
    "            return self.observation, 0, False, None\n",
    "        \n",
    "        self.observation[0, i_task] = 0\n",
    "        i_next_task = self.get_next_task(i_task)\n",
    "        if i_next_task:\n",
    "            self.observation[1, i_next_task] = 1\n",
    "        \n",
    "        task_finish_time = self.sim.resume(self.tasks[i_task])\n",
    "        reward = 1 / task_finish_time\n",
    "        \n",
    "        done = np.sum(self.observation[0]) == 0\n",
    "        return self.observation, reward, done, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task group: {0: [0, 1], 1: [2], 2: [3]}\n",
      "Equip map: {0: 0, 1: 0, 2: 1, 3: 2}\n",
      "Current observation: \n",
      "[[1 1 1 1]\n",
      " [1 0 1 1]]\n",
      "Selectable tasks: [0 2 3], selected 0, reward is 0.011627906976744186.\n",
      "Current observation: \n",
      "[[0 1 1 1]\n",
      " [1 1 1 1]].\n",
      "Selectable tasks: [1 2 3], selected 1, reward is 0.009433962264150943.\n",
      "Current observation: \n",
      "[[0 0 1 1]\n",
      " [1 1 1 1]].\n",
      "Selectable tasks: [2 3], selected 2, reward is 0.006172839506172839.\n",
      "Current observation: \n",
      "[[0 0 0 1]\n",
      " [1 1 1 1]].\n",
      "Selectable tasks: [3], selected 3, reward is 0.004807692307692308.\n",
      "Current observation: \n",
      "[[0 0 0 0]\n",
      " [1 1 1 1]].\n",
      "Tasks finished.\n"
     ]
    }
   ],
   "source": [
    "env = Environment(tasks)\n",
    "print(f\"Task group: {env.task_group}\")\n",
    "print(f\"Equip map: {env.equip_map}\")\n",
    "print(f\"Current observation: \\n{env.observation}\")\n",
    "\n",
    "while True:\n",
    "    selectable_tasks = env.get_selectable_tasks()\n",
    "    if len(selectable_tasks) == 0:\n",
    "        break\n",
    "    new_observation, reward, done, _ = env.step(selectable_tasks[0])\n",
    "    print(f\"Selectable tasks: {selectable_tasks}, selected {selectable_tasks[0]}, reward is {reward}.\")\n",
    "    print(f\"Current observation: \\n{new_observation}.\")\n",
    "    if done:\n",
    "        print(f\"Tasks finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
